{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 266 kB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: tqdm\n",
      "Successfully installed tqdm-4.67.1\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Entries:   0%|          | 0/1345 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Entries: 100%|██████████| 1345/1345 [00:38<00:00, 35.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1345\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './newer/Full_turn/train_dataset_LLaVA_full_turn.jsonl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 155\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(mew))\n\u001b[1;32m    154\u001b[0m \u001b[38;5;66;03m# Write to the JSONL file\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./newer/Full_turn/train_dataset_LLaVA_full_turn.jsonl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m tqdm(output_lines, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWriting to JSONL\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    157\u001b[0m         f\u001b[38;5;241m.\u001b[39mwrite(line \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/llava/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './newer/Full_turn/train_dataset_LLaVA_full_turn.jsonl'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import requests\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "from io import BytesIO\n",
    "from tqdm import tqdm  # Import tqdm for progress bars\n",
    "\n",
    "# Directory to save images\n",
    "image_dir = './LlaVA_img_train'\n",
    "os.makedirs(image_dir, exist_ok=True)\n",
    "\n",
    "# Load the original JSON data\n",
    "with open('/workspace/First_turn_vlt5/test_dataset_bert_first_turn.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Prepare the JSONL output\n",
    "output_lines = []\n",
    "mew= []\n",
    "\n",
    "def download_and_resize_images(img_ids):\n",
    "    local_image_paths = []\n",
    "    for idx, img_id in enumerate(tqdm(img_ids, desc=\"Downloading/Resizing Images\", leave=False), start=1):\n",
    "        local_path = os.path.join(image_dir, img_id)\n",
    "\n",
    "        if os.path.exists(local_path):\n",
    "            # Check size to skip already resized images\n",
    "            try:\n",
    "                with Image.open(local_path) as image:\n",
    "                    if image.size == (384, 384):\n",
    "                        # print(f\"Already resized: {img_id}\")\n",
    "                        local_image_paths.append(local_path)\n",
    "                        continue\n",
    "                    # print(f\"Resizing already downloaded: {img_id}\")\n",
    "                    image = image.convert(\"RGB\")\n",
    "                    image = image.resize((384, 384))\n",
    "                    image.save(local_path)\n",
    "                    local_image_paths.append(local_path)\n",
    "            except UnidentifiedImageError:\n",
    "                print(f\"Skipping unidentifiable image file: {local_path}\")\n",
    "            continue\n",
    "\n",
    "        url = f\"https://xmrec.github.io/mturk_images/all_images/{img_id}\"\n",
    "        \n",
    "        # Download and save the image\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            # Open the image and resize it\n",
    "            image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "            image = image.resize((384, 384))\n",
    "            image.save(local_path)\n",
    "            \n",
    "            local_image_paths.append(local_path)\n",
    "            # print(f\"Downloaded and resized {idx}/{len(img_ids)}: {img_id}\")\n",
    "        except requests.HTTPError as e:\n",
    "            # print(f\"Skipping failed download {url}: {e}\")\n",
    "            # raise RuntimeError\n",
    "            continue\n",
    "        except UnidentifiedImageError:\n",
    "            # print(f\"Skipping unidentifiable downloaded image: {img_id}\")\n",
    "            # raise RuntimeError\n",
    "            continue\n",
    "    return local_image_paths\n",
    "\n",
    "def concatenate_images(image_paths, mew):\n",
    "    images = [Image.open(p) for p in image_paths]\n",
    "    widths, heights = zip(*(i.size for i in images))\n",
    "    image_width, image_height = images[0].size  # Assuming all images have the same size after resizing (384x384)\n",
    "\n",
    "    # Pad the images list to have 12 images\n",
    "    if len(images) < 12:\n",
    "        padding_image = Image.new(\"RGB\", (image_width, image_height), (0, 0, 0))  # Black padding image\n",
    "        for _ in range(12 - len(images)):\n",
    "            images.append(padding_image)\n",
    "\n",
    "    # Update dimensions after padding\n",
    "    widths, heights = zip(*(i.size for i in images))\n",
    "    total_width = sum(widths)\n",
    "    max_height = max(heights)\n",
    "\n",
    "    new_image = Image.new(\"RGB\", (total_width, max_height), (0, 0, 0))  # Create a blank canvas\n",
    "\n",
    "    # Paste images onto the canvas\n",
    "    x_offset = 0\n",
    "    for im in images:\n",
    "        new_image.paste(im, (x_offset, 0))\n",
    "        x_offset += im.size[0]\n",
    "\n",
    "    # Generate the concatenated file name\n",
    "    base_names = os.path.basename(image_paths[0])\n",
    "    concatenated_path = os.path.join(\"\", f\"/workspace/LlaVA_img_train/concatenated_{base_names}\")\n",
    "\n",
    "    # Check if a file with the same name exists\n",
    "    if os.path.exists(concatenated_path):\n",
    "        mew.append(concatenated_path)\n",
    "        # If the file exists, return its name\n",
    "        return f\"File already exists: {concatenated_path}\"\n",
    "    else:\n",
    "        # Save the new image\n",
    "        new_image.save(concatenated_path)\n",
    "        mew.append(concatenated_path)\n",
    "        return concatenated_path\n",
    "\n",
    "# Wrap the main loop with tqdm to show progress\n",
    "for entry in tqdm(data, desc=\"Processing Entries\"):\n",
    "    conversation_parts = [f\"Topic: {entry['topic']}\"]\n",
    "    all_images = []\n",
    "\n",
    "    # Collect all images from the conversation\n",
    "    for i in range(1, 5):  # Assuming a maximum of 4 turns\n",
    "        img_ids_key = f\"img_ids{i}\"\n",
    "        img_ids = entry.get(img_ids_key, [])\n",
    "        downloaded_images = download_and_resize_images(img_ids)\n",
    "        all_images.extend(downloaded_images)\n",
    "\n",
    "    # Concatenate all images into one\n",
    "    if all_images:\n",
    "        concatenated_image = concatenate_images(all_images, mew)\n",
    "      \n",
    "        all_images = [concatenated_image]\n",
    "\n",
    "    for i in range(1, 5):\n",
    "        question_key = f\"question{i}\"\n",
    "        answer_key = f\"answer{i}\"\n",
    "        \n",
    "        if question_key in entry and answer_key in entry:\n",
    "            conversation_parts.append(f\"GPT: {entry[question_key]}\")\n",
    "            if i == 1 and all_images:\n",
    "                conversation_parts.append('<image>')\n",
    "            conversation_parts.append(f\"USER: {entry[answer_key]}\")\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # Construct the full conversation\n",
    "    conversation = ' '.join(conversation_parts)\n",
    "\n",
    "    # Prepare the documents\n",
    "    documents = entry.get(\"related_dict\", [])\n",
    "    \n",
    "    # Create the new JSONL entry\n",
    "    new_entry = {\n",
    "        \"facet_id\": entry.get(\"facet_id\", \"\"),\n",
    "        \"images\": all_images,\n",
    "        \"conversation\": conversation,\n",
    "        \"documents\": documents\n",
    "    }\n",
    "    \n",
    "    # Append the JSONL line\n",
    "    output_lines.append(json.dumps(new_entry))\n",
    "\n",
    "print(len(mew))\n",
    "\n",
    "# Write to the JSONL file\n",
    "with open('./newer/Full_turn/train_dataset_LLaVA_full_turn.jsonl', 'w') as f:\n",
    "    for line in tqdm(output_lines, desc=\"Writing to JSONL\"):\n",
    "        f.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the JSON dataset\n",
    "with open(\"./First_turn/test_dataset_bert_first_turn.json\", \"r\") as json_file:\n",
    "    dataset = json.load(json_file)\n",
    "\n",
    "# Load the qrels file\n",
    "qrels = []\n",
    "with open(\"../../Bert_datas/qrels\", \"r\") as qrels_file:\n",
    "    for line in qrels_file:\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) == 4:\n",
    "            facet_id, _, clueweb_id, relevance = parts\n",
    "            qrels.append({\n",
    "                \"facet_id\": facet_id,\n",
    "                \"clueweb_id\": clueweb_id,\n",
    "                \"relevance\": int(relevance)\n",
    "            })\n",
    "\n",
    "# Process the dataset\n",
    "for entry in dataset:\n",
    "    # Extract the facet_id and remove the \"F\" prefix for matching\n",
    "    facet_id = entry[\"facet_id\"].lstrip(\"F\")\n",
    "    \n",
    "    # Filter qrels for this facet_id with relevance > 0\n",
    "    relevant_clueweb_ids = [\n",
    "        qrel[\"clueweb_id\"] for qrel in qrels\n",
    "        if qrel[\"facet_id\"] == facet_id and qrel[\"relevance\"] > 0\n",
    "    ]\n",
    "    \n",
    "    # Update the related_dict in the dataset entry\n",
    "    entry[\"related_dict\"] = relevant_clueweb_ids\n",
    "\n",
    "# Save the updated dataset back to a JSON file\n",
    "with open(\"./First_turn/test_dataset_bert_first_turn.json\", \"w\") as output_file:\n",
    "    json.dump(dataset, output_file, indent=4)\n",
    "\n",
    "print(\"Updated dataset saved to 'test_dataset_bert_singleturn.json'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llava",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
